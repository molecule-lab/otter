# Otter Server Environment Configuration
# Copy this file to .env and update the values

# Database connection URL (REQUIRED)
DB_CONNECTION_URL=postgresql://username:password@host:port/database

# AI provider (REQUIRED) - currently only "openai" supported
AI_PROVIDER=openai

# AI provider API key (REQUIRED)
# Get from your AI provider's dashboard
AI_PROVIDER_API_KEY=XXX_AI_PROVIDER_API_KEY

# Text chunk size for embeddings (default: 800, range: 400-1400)
# Check your AI provider's embedding model token limits
# Larger chunks = more context, smaller chunks = more precision
CHUNK_SIZE=800

# Overlap between chunks (default: 80, suggest 10% of CHUNK_SIZE)
# Helps maintain context across chunk boundaries
CHUNK_OVERLAP=80

# Max parallel AI API calls (default: 25)
# Check your AI provider's rate limits and adjust accordingly
# Higher values = faster processing, but may hit rate limits
# Recommended: 10-50 depending on your provider's limits
MAX_PARALLEL_AI_CALLS=25

# Server port (default: 3000)
PORT=3000

# Rate limit: max requests per minute (default: 100)
MAX_REQUEST_PER_MINUTE=100