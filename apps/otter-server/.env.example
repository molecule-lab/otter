# Otter Server Environment Configuration
# Copy this file to .env and update the values

# Runtime environment (REQUIRED)
# Valid values: development, staging, production (default: production)
NODE_ENV=development

# Database connection URL (REQUIRED)
DB_CONNECTION_URL=postgresql://username:password@host:port/database

# AI provider (REQUIRED) - currently only "openai" supported
AI_PROVIDER=openai

# AI provider API key (REQUIRED)
# Get from your AI provider's dashboard
AI_PROVIDER_API_KEY=XXX_AI_PROVIDER_API_KEY

# Text chunk size for embeddings (default: 1000, range: 400-1400)
# Check your AI provider's embedding model token limits
# Larger chunks = more context, smaller chunks = more precision
CHUNK_SIZE=1000

# Overlap between chunks (default: 100, suggest 10% of CHUNK_SIZE)
# Helps maintain context across chunk boundaries
CHUNK_OVERLAP=100

# Max parallel AI API calls (default: 25)
# Check your AI provider's rate limits and adjust accordingly
# Higher values = faster processing, but may hit rate limits
# Recommended: 10-50 depending on your provider's limits
MAX_PARALLEL_AI_CALLS=25

# Server port (default: 3000)
PORT=3000

# Rate limit: max requests per minute (default: 100)
MAX_REQUEST_PER_MINUTE=100

# Allowed origins for CORS (comma-separated)
# Used for cross-origin requests from frontend applications
ORIGINS=http://localhost:3001

# Base URL for the server (used for auth callbacks and redirects)
BASE_URL=http://localhost:3000

# Secret key for authentication (REQUIRED)
# Generate a secure random string for production
AUTH_SECRET=xxyaasseesxxx